
import Head from 'next/head'

<Head>
  <script>
    {
      `(function() {
         var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?e60fb290e204e04c5cb6f79b0ac1e697";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
       })();`
    }
  </script>
</Head>

![LangChain](https://pica.zhimg.com/50/v2-56e8bbb52aa271012541c1fe1ceb11a2_r.gif)




`Petals`以BitTorrent方式在家中运行超过100B的语言模型。

本教程介绍如何使用Langchain和[Petals](https://github.com/bigscience-workshop/petals)。

安装Petals[#](#install-petals "此标题的永久链接")
---------------------------------------

要使用Petals API，需要安装`petals`包。使用`pip3 install petals`进行安装。

```python
!pip3 install petals

```

导入[#](#imports "此标题的永久链接")
--------------------------

```python
import os
from langchain.llms import Petals
from langchain import PromptTemplate, LLMChain

```

设置环境API密钥[#](#set-the-environment-api-key "此标题的永久链接")
-----------------------------------------------------

请确保从抱抱脸（Huggingface）获取[API密钥](https://huggingface.co/docs/api-inference/quicktour#get-your-api-token)。

```python
from getpass import getpass

HUGGINGFACE_API_KEY = getpass()

```

```python
os.environ["HUGGINGFACE_API_KEY"] = HUGGINGFACE_API_KEY

```

Create the Petals instance[#](#create-the-petals-instance "Permalink to this headline")
---------------------------------------------------------------------------------------

You can specify different parameters such as the model name, max new tokens, temperature, etc.

```python
# this can take several minutes to download big files!

llm = Petals(model_name="bigscience/bloom-petals")

```

```python
Downloading:   1%|▏                        | 40.8M/7.19G [00:24<15:44, 7.57MB/s]

```

创建提示词模板Create a Prompt Template[#](#create-a-prompt-template "Permalink to this headline")
-----------------------------------------------------------------------------------

我们将添加一个QA提示词模板
We will create a prompt template for Question and Answer.

```python
template = """Question: {question}

Answer: Let's think step by step."""

prompt = PromptTemplate(template=template, input_variables=["question"])

```

初始化LLMChain Initiate the LLMChain[#](#initiate-the-llmchain "Permalink to this headline")
-----------------------------------------------------------------------------

```python
llm_chain = LLMChain(prompt=prompt, llm=llm)

```

启动LLMChain Run the LLMChain[#](#run-the-llmchain "Permalink to this headline")
-------------------------------------------------------------------

启动LLMChain问一个问题。

```python
question = "What NFL team won the Super Bowl in the year Justin Beiber was born?"

llm_chain.run(question)

```

